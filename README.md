
# BI Country Data Pipeline ğŸŒ

This project extracts, transforms, and loads (ETL) country profile data from the [REST Countries API](https://restcountries.com) into Google BigQuery. The data is modeled into meaningful dimension and fact tables for analytics purposes.

---

## ğŸ“ Project Structure

```
Python BI Automation to BigQuery/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Main ETL pipeline logic
â”‚   â”œâ”€â”€ api_connector.py       # API connection and normalization
â”‚   â””â”€â”€ load_bq.py             # Loads final DataFrames to BigQuery
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Backup of raw JSON data
â”‚   â””â”€â”€ process/               # (Optional) space for transformed files
â”‚
â”œâ”€â”€ credentials/
â”‚   â””â”€â”€ BigQuery/              # GCP service account JSON
â”‚
â”œâ”€â”€ .env                       # Environment variables (see below)
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # You're here!
```

---

## âš™ï¸ Environment Configuration (`.env`)

The project uses `python-dotenv` to load sensitive variables. Your `.env` file should include:

```env
GOOGLE_APPLICATION_CREDENTIALS=credentials/BigQuery/<your-json>.json
GCP_PROJECT_ID=bi-country-data-pipeline
GCP_DATASET=dim_fact_restcountries
BQ_DATASET_ID=bi-country-data-pipeline.dim_fact_restcountries
```

---

## ğŸ”„ ETL Process Overview

### ğŸ”¹ Extraction
Data is pulled using `requests.get()` from:
```
https://restcountries.com/v3.1/all
```

### ğŸ”¹ Transformation
Using `pandas` and `json_normalize`:
- Nested fields are flattened
- Key columns extracted: languages, lat/lng, capital, gini, etc.
- Several fact/dim tables created

### ğŸ”¹ Load
Each final DataFrame is loaded to BigQuery via `pandas_gbq.to_gbq()` with `if_exists="replace"`.

---

## ğŸ§± Final Tables in BigQuery

| Table Name                    | Description                                  |
|------------------------------|----------------------------------------------|
| `df_country_media`           | URLs for flags, maps, and coat of arms       |
| `df_countries`               | Country name and capital                     |
| `df_languages`               | Country-to-language breakdown                |
| `df_fct_state_profile`       | Area, population, borders, lat/lng, density  |
| `df_fct_state_gini`          | GINI index by country and year               |

---

## â–¶ï¸ How to Run

```bash
# Install dependencies
pip install -r requirements.txt

# Run ETL & load
python app/load_bq.py
```

---

## ğŸ§  Ideas for Next Steps

- Add logging and error handling
- Automate via Airflow / Cloud Functions
- Versioning strategy for changing schemas
- Implement unit tests for API + transformation

---

## ğŸ“Œ Author

Created by [×ª×•×] as a learning project to automate ETL into BigQuery and improve cloud-based BI workflows.
