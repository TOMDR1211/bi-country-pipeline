# ğŸ›°ï¸ BI Automation to BigQuery

ETL pipeline written in Python that pulls data from the [RESTCountries API](https://restcountries.com/), processes it with `pandas`, and loads it into Google BigQuery.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api_connector.py     # Pulls data from the REST API
â”‚   â”œâ”€â”€ main.py              # Handles transformation and DataFrame creation
â”‚   â””â”€â”€ load_bq.py           # Loads processed data into BigQuery
â”‚
â”œâ”€â”€ credentials/
â”‚   â””â”€â”€ BigQuery/            # Holds the service account key (not pushed)
â”‚
â”œâ”€â”€ .env                     # Environment variables (ignored in .gitignore)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§° Tech Stack

- **Python**: `pandas`, `pandas-gbq`, `python-dotenv`
- **BigQuery**: Google Cloud project with service account authentication

---

## ğŸ”‘ Setup

1. **Clone the repo**  
   ```bash
   git clone https://github.com/TOMDR1211/bi-country-pipeline.git
   cd bi-country-pipeline
   ```

2. **Create and activate virtual environment**  
   ```bash
   python -m venv venv
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   ```

3. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables in `.env`**  
   ```env
   GCP_PROJECT_ID=your-project-id
   BQ_DATASET_ID=your-dataset-id
   GOOGLE_APPLICATION_CREDENTIALS=path/to/your/credentials.json
   ```

---

## ğŸš€ Run

```bash
python app/main.py       # Pull + Transform
python app/load_bq.py    # Load to BigQuery
```

---

## ğŸ“Œ Notes

- The `.gitignore` prevents credentials and sensitive files from being tracked.
- All data transformations are done with `pandas` prior to upload.

---

## ğŸ“„ License

MIT License